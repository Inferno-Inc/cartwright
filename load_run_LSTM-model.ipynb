{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offshore-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "import os\n",
    "from io import open\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "import operator\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "# Kyle's attempt\n",
    "import faker\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from string import punctuation\n",
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "certain-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1)\n",
    "\n",
    "        self.hidden2out = nn.Linear(hidden_dim, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=0.2)\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return(autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)),\n",
    "                    autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)))\n",
    "\n",
    "\n",
    "    def forward(self, batch, lengths):\n",
    "\n",
    "        self.hidden = self.init_hidden(batch.size(-1))\n",
    "\n",
    "        embeds = self.embedding(batch)\n",
    "        packed_input = pack_padded_sequence(embeds, lengths)\n",
    "        outputs, (ht, ct) = self.lstm(packed_input, self.hidden)\n",
    "        # ht is the last hidden state of the sequences\n",
    "        # ht = (1 x batch_size x hidden_dim)\n",
    "        # ht[-1] = (batch_size x hidden_dim)\n",
    "        output = self.dropout_layer(ht[-1])\n",
    "        output = self.hidden2out(output)\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "posted-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "class PaddedTensorDataset(Dataset):\n",
    "#     \"\"\"Dataset wrapping data, target and length tensors.\n",
    "\n",
    "#     Each sample will be retrieved by indexing both tensors along the first\n",
    "#     dimension.\n",
    "\n",
    "#     Arguments:\n",
    "#         data_tensor (Tensor): contains sample data.\n",
    "#         target_tensor (Tensor): contains sample targets (labels).\n",
    "#         length (Tensor): contains sample lengths.\n",
    "#         raw_data (Any): The data that has been transformed into tensor, useful for debugging\n",
    "#     \"\"\"\n",
    "\n",
    "    def __init__(self, data_tensor, target_tensor, length_tensor, raw_data):\n",
    "        assert data_tensor.size(0) == target_tensor.size(0) == length_tensor.size(0)\n",
    "        self.data_tensor = data_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "        self.length_tensor = length_tensor\n",
    "        self.raw_data = raw_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tensor[index], self.target_tensor[index], self.length_tensor[index], self.raw_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "atomic-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DF_To_Tensors():\n",
    "    def __init__(self):\n",
    "        self.tag2id = defaultdict(int,\n",
    "                        {'city': 0,\n",
    "                         'first_name': 1,\n",
    "                         'geo': 2,\n",
    "                         'percent': 3,\n",
    "                         'year': 4,\n",
    "                         'date': 5,\n",
    "                         'ssn': 6,\n",
    "                         'language_name': 7,\n",
    "                         'country': 8,\n",
    "                         'phone_number': 9,\n",
    "                         'month': 10,\n",
    "                         'zipcode': 11,\n",
    "                         'iso8601': 12,\n",
    "                         'paragraph': 13,\n",
    "                         'pyfloat': 14,\n",
    "                         'email': 15,\n",
    "                         'prefix': 16,\n",
    "                         'pystr': 17,\n",
    "                         'isbn': 18,\n",
    "                         'boolean': 19,\n",
    "                        'country_code': 20,\n",
    "                        'continent':21})\n",
    "        self.n_categories = len(self.tag2id)\n",
    "        self.token_set={'a','b','c','d','e',\n",
    "                        'f','g','h','i','j','k','l',\n",
    "                        'm','n','o','p','q','r','s',\n",
    "                        't','u','v','w','x','y','z',\n",
    "                        'A','B','C','D','E','F','G',\n",
    "                        'H','I','J','K','L','M','N',\n",
    "                        'O','P','Q','R','S','T','U',\n",
    "                        'V','W','X','Y','Z','1','2',\n",
    "                        '3','4','5','6','7','8','9','0',\n",
    "                        \"'\",',','.',';','*','!','@',\n",
    "                        '#','$','%','^','&','(',')',\n",
    "                        '_','=','-',':','+','/',\"\\\\\", '*'}\n",
    "        self.token2id = defaultdict(int,\n",
    "            {'PAD': 0,\n",
    "             'UNK': 1,\n",
    "             'a':2,\n",
    "             'b':3,\n",
    "             'c': 4,\n",
    "             'd': 5,\n",
    "             'e': 6,\n",
    "             'f': 7,\n",
    "             'g':8,\n",
    "             'h': 9,\n",
    "             'i': 10,\n",
    "             'j':11,\n",
    "             'k':12,\n",
    "             'l':13,\n",
    "             'm':14,\n",
    "             'n':15,\n",
    "             'o':16,\n",
    "             'p':17,\n",
    "             'q':18,\n",
    "             'r':19,\n",
    "             's':20,\n",
    "             't':21,\n",
    "             'u':22,\n",
    "             'v':23,\n",
    "             'w':24,\n",
    "             'x':25,\n",
    "             'y':26,\n",
    "             'z':27,\n",
    "             'A':28,\n",
    "             'B':29,\n",
    "             'C':30,\n",
    "             'D':31,\n",
    "             'E':32,\n",
    "             'F':33,\n",
    "             'G':34,\n",
    "             'H':35,\n",
    "             'I':36,\n",
    "             'J':37,\n",
    "             'K':38,\n",
    "             'L':39,\n",
    "             'N':40,\n",
    "             'O':41,\n",
    "             'P':42,\n",
    "             'Q':43,\n",
    "             'R':44,\n",
    "             'S':45,\n",
    "             'T':46,\n",
    "             'U':47,\n",
    "             'V':48,\n",
    "             'W':49,\n",
    "             'X':50,\n",
    "             'Y':51,\n",
    "             'Z':52,\n",
    "             '1':53,\n",
    "             '2':54,\n",
    "             '3':55,\n",
    "             '4':56,\n",
    "             '5':57,\n",
    "             '6':58,\n",
    "             '7':59,\n",
    "             '8':60,\n",
    "             '9':61,\n",
    "             '0':62,\n",
    "             \"'\":63,\n",
    "             ',':64,\n",
    "             '.':65,\n",
    "             ';':66,\n",
    "             '*':67,\n",
    "             '!':68,\n",
    "             '@':68,\n",
    "             '#':70,\n",
    "             '$':71,\n",
    "             '%':72,\n",
    "             '^':73,\n",
    "             '&':74,\n",
    "             '(':75,\n",
    "             ')':76,\n",
    "             '_':77,\n",
    "             '=':78,\n",
    "             '-':79,\n",
    "             ':':80,\n",
    "             '+':81,\n",
    "             '/':82,\n",
    "             '\\\\':83,\n",
    "             '*': 84})\n",
    "    \n",
    "    def vectorized_string(self, string):\n",
    "            return [self.token2id[token] if token in self.token2id else self.token2id['UNK'] for token in str(string)]\n",
    "        \n",
    "    def vectorized_array(self, array):\n",
    "        vecorized_array=[]\n",
    "        for stringValue in array:\n",
    "            vecorized_array.append(self.vectorized_string(stringValue))\n",
    "        return vecorized_array\n",
    "    \n",
    "    def pad_sequences(self, vectorized_seqs, seq_lengths):\n",
    "        # create a zero matrix\n",
    "        seq_tensor = torch.zeros((len(vectorized_seqs), seq_lengths.max())).long()\n",
    "\n",
    "        # fill the index\n",
    "        for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "            seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
    "        return seq_tensor\n",
    "\n",
    "\n",
    "    def create_dataset(self, data, batch_size=1):\n",
    "        vectorized_seqs = self.vectorized_array(data)\n",
    "        seq_lengths = torch.LongTensor([len(s) for s in vectorized_seqs])\n",
    "        seq_tensor = self.pad_sequences(vectorized_seqs, seq_lengths)\n",
    "        target_tensor = torch.LongTensor([self.tag2id[y] for  y in data])\n",
    "        raw_data = [x for x in data]\n",
    "        \n",
    "        return DataLoader(PaddedTensorDataset(seq_tensor, target_tensor, seq_lengths, raw_data), batch_size=batch_size)\n",
    "\n",
    "    def sort_batch(self,batch, targets, lengths):\n",
    "        seq_lengths, perm_idx = lengths.sort(0, descending=True)\n",
    "        seq_tensor = batch[perm_idx]\n",
    "        target_tensor = targets[perm_idx]\n",
    "\n",
    "        return seq_tensor.transpose(0, 1), target_tensor, seq_lengths\n",
    "\n",
    "\n",
    "    def evaluate_test_set(self, model, test):\n",
    "        y_pred = list()\n",
    "        all_predictionsforValue=[]\n",
    "\n",
    "        for batch, targets, lengths, raw_data in self.create_dataset(test, batch_size=1):\n",
    "            batch, targets, lengths = self.sort_batch(batch, targets, lengths)\n",
    "            pred = model(torch.autograd.Variable(batch), lengths.cpu().numpy())\n",
    "            pred_idx = torch.max(pred, 1)[1]\n",
    "            print('pred_idx', pred_idx)\n",
    "            def get_key(val):\n",
    "                for key, value in self.tag2id.items():\n",
    "                     if val == value:\n",
    "                            print(key)\n",
    "                            return {'key':key, 'tensor':pred, 'pred_idx':pred_idx}\n",
    "#                             all_predictionsforValue.append({'key':key, 'tensor':pred, 'pred_idx':pred_idx})\n",
    "\n",
    "            all_predictionsforValue.append(get_key(pred_idx[0]))\n",
    "        return all_predictionsforValue\n",
    "        \n",
    "    def read_in_csv(self,path):\n",
    "        self.df = pd.read_csv(path)\n",
    "#         print(self.df.head())\n",
    "    \n",
    "    def get_arrayOfValues_df(self):\n",
    "        import time\n",
    "        column_value_object={}\n",
    "\n",
    "        for column in self.df.columns:\n",
    "            guesses=[]\n",
    "            column_value_object[column]=[]\n",
    "            for _ in range(1,3):\n",
    "                random_values = str(np.random.choice(self.df[column]))\n",
    "                random_col = column\n",
    "                column_value_object[column].append(str(random_values)) \n",
    "\n",
    "        return column_value_object\n",
    "    \n",
    "    def predictions(self, model, path_to_csv):\n",
    "        self.read_in_csv(path=path_to_csv)\n",
    "        column_value_object = self.get_arrayOfValues_df()\n",
    "        for column in column_value_object:\n",
    "            print(column_value_object[column])\n",
    "            print(column)\n",
    "            print(self.evaluate_test_set(model, column_value_object[column]))\n",
    "#             return {\n",
    "#                 'column': column,\n",
    "#                 'values': column_value_object[column],\n",
    "#                 'predictions': self.evaluate_test_set(column_value_object[column])\n",
    "#             }\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "minimal-chick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (embedding): Embedding(84, 128)\n",
       "  (lstm): LSTM(128, 32)\n",
       "  (hidden2out): Linear(in_features=32, out_features=22, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       "  (dropout_layer): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create our class and load the saved model\n",
    "dft_tensor=DF_To_Tensors()\n",
    "model = torch.load('./models/LSTM_RNN_classifier_model_5.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_tensor.predictions(model=model, path_to_csv='datasets/data/africa_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_tensor.predictions(model=model, path_to_csv='datasets/data/four_col_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "stone-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just test a random array by itself.\n",
    "dft_tensor.evaluate_test_set(model=model,test=['01/02/2020', '09', 'USA', 'WOWOOWOWOWOWOWOWO', '1999', '1200', '402', '.3934', 'iiii', '12', 'USA',\"ETH\",'South America'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "equivalent-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for later use\n",
    "def randomChoice(self, values):\n",
    "    return values[random.randint(0, len(values) - 1)]\n",
    "\n",
    "def getRandomSet(self):\n",
    "    category = self.randomChoice(self.all_categories)\n",
    "#         print(category)\n",
    "    line = self.randomChoice(list(self.category_values[category]['obj']))\n",
    "#         print('line', line)\n",
    "    return (line, category)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
